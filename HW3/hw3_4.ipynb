{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "from text_utils import TextLoader\n",
    "%run text_utils.py\n",
    "from tensorflow.contrib import rnn\n",
    "from char_rnn_model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define directories, hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir  = './'\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LEN = 16\n",
    "encoding='utf-8'\n",
    "hidden_layer = 256\n",
    "learning_rate = 0.001 \n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data using TextLoader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (12504, 16, 16, 1) (12504, 16, 1)\n",
      "Val  : (1787, 16, 16, 1) (1787, 16, 1)\n",
      "Test : (3573, 16, 16, 1) (3573, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "textloader = TextLoader(data_dir, BATCH_SIZE, SEQ_LEN, encoding)\n",
    "X_train = np.asarray(textloader.x_batches[:int(textloader.num_batches*0.7),:,:,:])\n",
    "y_train = np.asarray(textloader.y_batches[:int(textloader.num_batches*0.7),:,:])\n",
    "X_val = np.asarray(textloader.x_batches[int(textloader.num_batches*0.7):int(textloader.num_batches*0.8),:,:,:])\n",
    "y_val = np.asarray(textloader.y_batches[int(textloader.num_batches*0.7):int(textloader.num_batches*0.8),:,:])\n",
    "X_test = np.asarray(textloader.x_batches[int(textloader.num_batches*0.8):,:,:,:])\n",
    "y_test = np.asarray(textloader.y_batches[int(textloader.num_batches*0.8):,:,:])\n",
    "\n",
    "print(\"Train:\",X_train.shape,y_train.shape)\n",
    "print(\"Val  :\",X_val.shape,y_val.shape)\n",
    "print(\"Test :\",X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place holders\n",
    "X = tf.placeholder(tf.float32, [BATCH_SIZE, SEQ_LEN, 1])\n",
    "Y = tf.placeholder(tf.float32, [BATCH_SIZE, 1])\n",
    "\n",
    "#Define LSTM\n",
    "#input gate\n",
    "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
    "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
    "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
    "#forget gate\n",
    "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
    "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
    "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
    "#output gate\n",
    "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
    "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
    "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
    "#memory cell\n",
    "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
    "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
    "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
    "\n",
    "## Output layer weigts\n",
    "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
    "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "def LSTM_cell(input, output, state):\n",
    "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)    \n",
    "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)    \n",
    "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
    "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
    "    state = state * forget_gate + input_gate * memory_cell \n",
    "    output = output_gate * tf.tanh(state)\n",
    "    return state, output\n",
    "\n",
    "outputs = []\n",
    "for i in range(BATCH_SIZE):\n",
    "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32) \n",
    "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
    "    for j in range(SEQ_LEN):\n",
    "        batch_state, batch_output = LSTM_cell(tf.reshape(X[i][j], (-1, 1)), batch_state, batch_output)\n",
    "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
    "losses = []\n",
    "for i in range(len(outputs)):\n",
    "    losses.append(tf.losses.mean_squared_error(tf.reshape(Y[i], (-1, 1)), outputs[i]))\n",
    "    \n",
    "loss = tf.reduce_mean(losses)\n",
    "gradients = tf.gradients(loss, tf.trainable_variables())\n",
    "clipped, _ = tf.clip_by_global_norm(gradients, 4)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100 Training loss: 91.37164306640625 Val loss: 82.60543060302734\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "for i in range(epochs):\n",
    "    traind_scores = []\n",
    "    epoch_loss = []\n",
    "    val_epoch_loss = []\n",
    "    for j in range(X_train.shape[0]):\n",
    "        X_batch = X_train[j,:,:,:]\n",
    "        y_batch = y_train[j,:,:]\n",
    "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={X:X_batch, Y:y_batch})     \n",
    "        epoch_loss.append(c)\n",
    "        traind_scores.append(o)\n",
    "    for j in range(X_val.shape[0]):\n",
    "        X_batch = X_val[j,:,:,:]\n",
    "        y_batch = y_val[j,:,:]\n",
    "        c = session.run([loss], feed_dict={X:X_batch, Y:y_batch})     \n",
    "        val_epoch_loss.append(c)\n",
    "        \n",
    "    if (i % 10) == 0:\n",
    "        print('Epoch {}/{}'.format(i, epochs), 'Training loss: {}'.format(np.mean(epoch_loss)), 'Val loss: {}'.format(np.mean(val_epoch_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for j in range(X_test.shape[0]):\n",
    "    o = session.run([outputs], feed_dict={X:X_test[j,:,:,:]})\n",
    "    preds.append(o)\n",
    "preds = np.squeeze(np.asarray(preds)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
